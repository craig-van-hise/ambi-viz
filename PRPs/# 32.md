# Product Requirements Prompt (PRP): Stationary World & Orientation Recovery

## 1. Project Context & Objectives
The objective is to pivot the "Inside View" logic. Instead of the head tracker rotating the Three.js camera (which causes motion sickness on flat screens), the camera will remain fixed at the origin $(0,0,0)$ looking forward. The user's head movement will instead be visualized by the "Actual" and "Ghost" 3D arrows (nose-pointer logic) and used to rotate the Ambisonic sound field.

**Key Goals:**
* **Stationary Horizon:** Lock the 3D scene camera while tracking is active in Inside View.
* **Acoustic Realism:** Fix the Yaw inversion so that looking left correctly shifts the sound stage to the right ear.
* **Visual Alignment:** Synchronize the 3D arrow meshes to point exactly where the user's nose is pointing.
* **UI Telemetry:** Ensure sliders reflect the tracker's state without feeding back into camera movement.

## 2. Technical Decisions & Dependencies
* **Coordinate Mapping:** * **Audio Yaw:** Send `-yaw` (inverted) to the `OBRDecoder` or the `SharedArrayBuffer` feeding the worklet.
    * **Visual Pitch/Yaw:** The arrow meshes must mirror the tracker's Euler angles. If tracker returns $+15^\circ$ Yaw (Left), the arrow mesh `rotation.y` must reflect the visual equivalent in Three.js space to point left.
* **Camera State Management:** Introduce a conditional check in the `animate` loop: `if (viewMode === 'inside' && isTracking) { camera.quaternion.set(0, 0, 0, 1); }`.
* **Input Decoupling:** The `useHeadTracking` hook or `HeadTrackingService` must continue updating the global state/SAB, but the `AmbiScene` must ignore these values for `camera` rotation, applying them only to `arrowGroup`.

## 3. Implementation Phases

### Phase 1: Camera Decoupling & Origin Lock
* **Objective:** Prevent head tracking from rotating the visual camera in "Inside View."
* **Instructions:**
    1.  Modify `AmbiScene.ts` (or the component handling the Three.js render loop).
    2.  Locate the logic that applies `headRotation` to the `camera`.
    3.  Wrap this logic in a condition: only apply tracker rotation to the camera if `viewMode === 'outside'`.
    4.  If `viewMode === 'inside'` and `isTracking` is true, explicitly call `camera.rotation.set(0, 0, 0)` and `camera.position.set(0, 0, 0)` every frame to override `OrbitControls` or drift.
* **TDD Checkpoint:**
    * **Test Case 1:** Given `viewMode: 'inside'` and `isTracking: true`, When `HeadTrackingService` emits a non-zero rotation, Assert `camera.quaternion` remains `(0,0,0,1)`.
    * **Test Case 2:** Given `viewMode: 'outside'`, When tracking is active, Assert `camera` orientation is updated (or remains controllable via OrbitControls as per design).
    * **AGENT INSTRUCTION:** "Ensure the camera is perfectly still in Inside View before proceeding. The world should not move when you move your head."

### Phase 2: Audio Yaw Inversion (The "Look Left" Fix)
* **Objective:** Align the binaural soundstage with stationary world logic.
* **Instructions:**
    1.  Locate the data pipeline in `OBRDecoder.ts` or `HeadTrackingService.ts` where orientation is written to the `SharedArrayBuffer`.
    2.  Apply a sign flip to the **Yaw** component: `finalYaw = -rawYaw`. 
    3.  Keep Pitch and Roll as currently implemented unless audio testing suggests further mirroring.
* **TDD Checkpoint:**
    * **Test Case 1:** Given a tracker Yaw of `+0.5` rad (Left), When data is sent to OBR, Assert the value in the SAB is `-0.5`.
    * **Test Case 2:** Functional verification: "Looking Left" must result in audio energy increasing in the **Right** ear (as the sound source 'moves' relative to the head).
    * **AGENT INSTRUCTION:** "Verify the sign flip in the unit tests for OBR orientation updates. Do not proceed until the math is inverted."

### Phase 3: Visual Arrow Alignment (Nose-Pointer Logic)
* **Objective:** Ensure 3D arrows follow the user's physical nose direction.
* **Instructions:**
    1.  In `AmbiScene.ts`, identify the `ActualArrow` and `GhostArrow` (Predicted) meshes.
    2.  Update their rotation logic. If the user tilts their head UP, the arrow points UP. If they look LEFT, the arrow points LEFT.
    3.  Apply the inverse of the camera-fix: These arrows *must* receive the raw/predicted ESKF Euler angles directly.
    4.  Formula: `arrow.rotation.set(tracker.pitch, tracker.yaw, tracker.roll)`. (Note: You may need to swap axes depending on Three.js Y-up vs. MediaPipe coordinate systems).
* **TDD Checkpoint:**
    * **Test Case 1:** Given tracker Pitch `+20deg` (Up), Assert Arrow Mesh `rotation.x` reflects an upward tilt.
    * **Test Case 2:** Given tracker Yaw `-15deg` (Right), Assert Arrow Mesh points toward the right side of the 3D canvas.
    * **AGENT INSTRUCTION:** "Visually confirm that the green/ghost arrows behave like a laser pointer attached to your nose."

### Phase 4: UI Telemetry & Interaction Hardening
* **Objective:** Sync React sliders to tracker data in a read-only state during tracking.
* **Instructions:**
    1.  In `App.tsx` or `TransportControls.tsx`, ensure the Yaw/Pitch/Roll sliders reflect the *tracker's* values when `isTracking` is true.
    2.  Disable manual slider input (CSS `pointer-events: none` or React `disabled` prop) while tracking is active to prevent state-fighting.
    3.  Ensure `OrbitControls` in "Outside View" does not conflict with the arrow visualizations.
* **TDD Checkpoint:**
    * **Test Case 1:** Given `isTracking: true`, When head moves, Assert UI sliders update their positions automatically.
    * **Test Case 2:** Given `isTracking: true`, Assert manual slider dragging is blocked or ignored.

## 4. Final Review
1.  **Stationary Check:** Does the grid/background stay still in Inside View?
2.  **Audio Check:** Does looking toward a visual sound peak move that peak to the center of the stereo image? (i.e., Look Left -> Sound moves from Left Ear to Center).
3.  **Visual Check:** Do the arrows perfectly track head movement without lag or inversion?
4.  **Regression Check:** Does "Outside View" still allow orbital navigation?

**AGENT INSTRUCTION:** "Once all phases are complete, run the full Vitest suite. Ensure no previous OBR or ESKF tests are broken by the sign-flip changes."