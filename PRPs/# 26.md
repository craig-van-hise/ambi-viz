
# Product Requirements Prompt (PRP)

## 1. Project Context & Objectives

Address visual-cognitive dissonance in the 3DOF interface. The objective is to align the Green Pointer and Horizon movements with user expectations in a "Non-VR" context while maintaining the integrity of the **Google OBR Renderer** orientation.

## 2. Technical Decisions & System Integrity

* **Audio Integrity (Hands-Off):** The `OBRDecoder` must continue to receive raw, uninverted Yaw, Pitch, and Roll from the tracking service to ensure the spatial audio remains anchored to the physical world.
* **Visual Inversion (The Lens):** We will invert the **Camera's** pitch and roll projection. In a Non-VR screen, when a user tilts their head up, the camera tilts up. This naturally makes the world (and the horizon) move **down** on the screen.
* **Pointer Mapping:** The Green Pointer is a UI element. To act as a "Gaze Indicator," it must be mapped $1:1$ to the head's displacement. If the head moves $+Y$ (up), the pointer moves $+Y$.
* **Roll Philosophy:** We will use a **Camera-Relative Roll**. The camera rolls with the head, causing the visual horizon to tilt in the opposite direction (simulating a fixed world seen through a tilting cockpit).

## 3. Implementation Phases

### Phase 1: Decoupled Orientation Dispatch

* **Objective:** Ensure the Audio Engine and the Visualizer receive the specific data they need without interference.
* **Instructions:**
1. In `HeadTrackingService.ts`, maintain a "Source of Truth" orientation object.
2. **Audio Path:** Dispatch raw `yaw`, `pitch`, `roll` directly to the `OBRDecoder`.
3. **Visual Path:** Pass these same values to `AmbiScene.ts`.


* **TDD Checkpoint:**
* **AGENT INSTRUCTION:** Write a test asserting that `OBRDecoder.updateRotation` receives the exact same values produced by the ESKF, regardless of UI settings.



### Phase 2: Visual Horizon & Camera Hardening

* **Objective:** Implement "Cockpit View" logic where the camera moves, not the world.
* **Instructions:**
1. In `AmbiScene.ts`, update the camera rotation:
* `camera.rotation.x = -pitch;` (Inverting pitch for the camera makes the *visuals* move correctly).
* `camera.rotation.y = -yaw;`.


2. **Roll Fix:** To simulate the horizon tilting correctly on a flat screen, apply roll to the `camera.up` vector:
* `camera.up.set(-Math.sin(roll), Math.cos(roll), 0);`.


3. Keep the **Inside View** camera position locked at `(0, 0, 0)`.


* **TDD Checkpoint:**
* **AGENT INSTRUCTION:** Verify that when `pitch > 0` (looking up), the 3D Horizon's screen-space Y-coordinate decreases (moves down).



### Phase 3: Green Pointer UI Mapping

* **Objective:** Align the Green Pointer to act as a gaze-following instrument.
* **Instructions:**
1. The Green Pointer should **not** be a child of the 3D Camera. It should be a 2D UI overlay or a fixed-position sprite in front of the camera.
2. Map its position: `pointer.style.transform = translate(${yaw_pixels}px, ${-pitch_pixels}px)`.
3. This ensures that when the user looks "up," the pointer moves "up" toward the top of the physical monitor, even as the 3D scene behind it tilts downward.


* **TDD Checkpoint:**
* **AGENT INSTRUCTION:** Mock a "Pitch Up" event and confirm the Green Pointer element's CSS `top` or `translateY` value moves toward the top of the viewport.



## 4. Final Review

* **Audio Check:** Use a test ambisonic file with a single point source at the "Front." Rotate your head; the sound should stay fixed in the "World Front" regardless of the new UI pointer behavior.
* **Visual Check:** Confirm the Green Pointer follows your gaze (up = up) while the Horizon moves like a real-world window (up = horizon goes down).
* **Consistency:** Ensure `ROLL` is now reactive in the UI and correctly tilting the view without breaking the OBR spatialization.

