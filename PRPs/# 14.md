# Product Requirements Prompt (PRP)

## 1. Project Context & Objectives
You are debugging and refactoring the Web Audio transport and ingestion pipeline for the AmbiViz application. The current implementation suffers from race conditions between React state and the `AudioContext`, unhandled Promise rejections during `decodeAudioData` (causing silent ingestion failures), and an unintuitive track queue that requires redundant clicks.

Your objective is to implement a strict state machine in `AudioEngine.ts`, add a `loading`/`error` UI state, and refactor the Web Audio `AudioBufferSourceNode` lifecycle to a Just-In-Time (JIT) creation pattern.

## 2. Technical Decisions & Dependencies
* **State Machine:** Expand `PlaybackState` to `'loading' | 'playing' | 'paused' | 'stopped' | 'error'`.
* **Web Audio Pattern (JIT Node Creation):** `AudioBufferSourceNode`s are strictly single-use. You will remove the `startFreshSource()` anti-pattern. Instead, the source node must *only* be instantiated, connected, and `start()`ed inside the `play()` method. The `stop()` method will strictly call `stop()` on the node, disconnect it, and nullify it.
* **Event Emission:** Implement a simple subscriber callback in `AudioEngine` (`onStateChange: (state: PlaybackState) => void`) to proactively push state changes to React, eliminating synchronization lag.

## 3. Implementation Phases

### Phase 1: Engine State Machine & Robust Decoding
* **Objective:** Prevent silent ingestion failures and implement precise audio state tracking.
* **Instructions:**
    1.  In `src/audio/AudioEngine.ts`, update the `PlaybackState` type:
        `export type PlaybackState = 'stopped' | 'playing' | 'paused' | 'loading' | 'error';`
    2.  Add a callback property to `AudioEngine`: `public onStateChange?: (state: PlaybackState) => void;`
    3.  Create a private helper `setState(state: PlaybackState)` that updates `this.playbackState` and invokes `this.onStateChange?.(state)`. Use this helper everywhere instead of directly mutating `this.playbackState`.
    4.  In `loadTrack(index: number)`, immediately call `this.setState('loading')`.
    5.  Wrap the `decodeAudioData` call inside a `try/catch` block. 
    6.  If decoding fails, catch the error, log it via `console.error`, set `this.setState('error')`, and `return` early. 
    7.  If successful, call `await this.setupGraph(...)` and finally `this.setState('stopped')`.
* **TDD Checkpoint:** AGENT INSTRUCTION: Open `src/audio/AudioEngine.test.ts`. Write a test that mocks `decodeAudioData` to reject. Assert that calling `loadTrack` successfully transitions the engine state to `'loading'` and then strictly to `'error'`. Do not proceed to Phase 2 until all tests in this checkpoint output a PASS.

### Phase 2: Web Audio Node Lifecycle Refactor
* **Objective:** Eliminate initialization lag by using Just-In-Time (JIT) source node creation.
* **Instructions:**
    1.  In `AudioEngine.ts`, completely remove the `startFreshSource()` method.
    2.  In `setupGraph()`, **remove** steps 2 and 3 (where `this.sourceNode` is created and assigned). `setupGraph` should only cache the `audioBuffer`, configure the `obrDecoder` and `rawAnalyser`, and ensure the context is resumed.
    3.  Rewrite `play()`:
        * If `this.playbackState === 'playing'`, do nothing.
        * If `this.audioCtx.state === 'suspended'`, await `this.audioCtx.resume()`.
        * If `this.sourceNode` is null (meaning we are playing from a stopped state), instantiate a new `AudioBufferSourceNode`, assign `this.audioBuffer`, set `loop`, connect it to `this.rawAnalyser!.in`, and call `this.sourceNode.start()`.
        * Call `this.setState('playing')`.
    4.  Rewrite `stop()`:
        * If `this.sourceNode` exists, call `try { this.sourceNode.stop(); } catch(e){}`, disconnect it, and set `this.sourceNode = null`.
        * Call `this.setState('stopped')`.
    5.  Rewrite `pause()`:
        * Call `this.audioCtx.suspend()`.
        * Call `this.setState('paused')`.
* **TDD Checkpoint:**
    AGENT INSTRUCTION: Write a test asserting that `play()` creates a new `AudioBufferSourceNode` and calls `start()` if `sourceNode` is null, and that `stop()` destroys the node without recreating it. Do not proceed to Phase 3 until all tests in this checkpoint output a PASS.

### Phase 3: UI Integration & Buffering Indicators
* **Objective:** Surface the new state machine to the user and fix queue interaction.
* **Instructions:**
    1.  In `src/components/TransportControls.tsx`, update the UI to handle `'loading'` and `'error'` states. Add a visual indicator (e.g., a disabled "Buffering..." button or spinner) when `playbackState === 'loading'`.
    2.  Disable all transport buttons (Play, Pause, Next, Prev) when the state is `'loading'` or `'error'`.
    3.  In `src/App.tsx` (or wherever `AudioEngine` is instantiated), bind to `engine.onStateChange` inside a `useEffect` to sync the engine's state to React state.
    4.  In the parent component managing the `TrackQueue`, modify the `onTrackSelect` handler so that it acts as a macro:
        ```typescript
        const handleTrackSelect = async (index: number) => {
            await engine.loadTrack(index);
            if (engine.playbackState !== 'error') {
                engine.play();
            }
        };
        ```
* **TDD Checkpoint:**
    AGENT INSTRUCTION: Verify the codebase using `npm run typecheck` or your equivalent TypeScript compiler command. Ensure all interface changes in `TransportControlsProps` and `PlaybackState` are satisfied across the component tree. Fix any TS errors before finalizing.

## 4. Final Review
1.  Verify that dropping an invalid file format (e.g., a text file renamed to .wav) no longer crashes the app but safely transitions to the `'error'` state.
2.  Verify that single-clicking a track in the queue immediately displays a loading indicator and auto-plays without requiring a secondary click.
3.  Confirm no orphaned `AudioBufferSourceNode` objects remain connected to the graph upon calling `stop()`.