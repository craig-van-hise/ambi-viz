# Product Requirements Prompt (PRP)

## 1. Project Context & Objectives
You are resolving a critical data-flow disconnect in the AmbiViz application. The `HeadTrackingService` correctly computes webcam quaternions and sends them to the AudioWorklet via a SharedArrayBuffer (SAB). However, this quaternion is never applied to the visual Three.js `camera` object. Consequently, the React `CameraControlPanel` sliders fail to reflect the user's physical head movements.

Your objective is to inject the SAB-driven quaternion into the Three.js camera inside the `AmbiScene` render loop, project the new `OrbitControls` target, and synchronize the resulting Euler angles to the React UI.

## 2. Technical Decisions & Dependencies
* **Data Flow Architecture:** The render loop (`AmbiScene.animate`) must become the central hub. It will read the `predQuat` from the SAB, apply it to the camera, update `OrbitControls`, and *then* dispatch the Euler angles to the UI.
* **Euler Extraction:** After applying the quaternion to the camera, you MUST read the resulting Euler angles using `camera.rotation` (ensuring `YXZ` order is preserved) and convert radians back to degrees for the UI sliders.
* **Slider Override Flag:** To prevent the webcam from fighting the user when they manually drag a slider, you must implement the `isDraggingSlider` boolean check. If true, the render loop must ignore the webcam quaternion and allow the slider to dictate the camera position.

## 3. Implementation Phases

### Phase 1: Inject Webcam Quaternion to Camera
* **Objective:** Apply the Head Tracker's output directly to the Three.js camera in real-time.
* **Instructions:**
    1. Open `src/visualizer/AmbiScene.ts`.
    2. Add a public property or method to receive the predicted quaternion from the main thread (e.g., `public headTrackingQuat: THREE.Quaternion | null = null;`).
    3. Ensure `this.camera.rotation.order = 'YXZ';` remains explicitly set in the constructor.
    4. Inside the `animate()` loop, add the following logic BEFORE `controls.update()`:
       ```javascript
       // Check if we have active head tracking data and the user is NOT dragging a slider
       if (this.viewMode === 'inside' && this.headTrackingQuat && !this.isUserDraggingSlider) {
           
           // Apply the webcam quaternion to the camera
           this.camera.quaternion.copy(this.headTrackingQuat);
           
           // Project the forward vector for OrbitControls to follow
           const forward = new THREE.Vector3(0, 0, -1);
           forward.applyQuaternion(this.camera.quaternion);
           this.controls.target.copy(forward);
           
           // Aggressively lock position
           this.camera.position.set(0, 0, 0);
       }
       ```

### Phase 2: Render Loop UI Synchronization
* **Objective:** Poll the updated camera rotation and send it to React.
* **Instructions:**
    1. In `AmbiScene.ts`, create a callback property: `public onCameraStateChange?: (state: any) => void;`.
    2. Inside the `animate()` loop, AFTER `controls.update()`, implement a throttled dispatch to send the state to React:
       ```javascript
       // Throttle this call (e.g., every 50ms) using your Throttle utility
       if (this.onCameraStateChange && !this.isUserDraggingSlider) {
           this.onCameraStateChange({
               // Convert Radians back to Degrees for the UI Sliders
               yaw: this.camera.rotation.y * (180 / Math.PI),
               pitch: this.camera.rotation.x * (180 / Math.PI),
               roll: this.camera.rotation.z * (180 / Math.PI),
               x: this.camera.position.x,
               y: this.camera.position.y,
               z: this.camera.position.z
           });
       }
       ```

### Phase 3: Parent Component Integration & State Fighting Prevention
* **Objective:** Wire the `AmbiScene` callbacks to the React state and handle the drag flags.
* **Instructions:**
    1. Open the parent component that instantiates `AmbiScene` (likely `App.tsx`).
    2. Pass the `onCameraStateChange` callback to the `AmbiScene` instance to update the `cameraUIState`.
    3. Ensure the `AmbiScene` `animate` loop is fed the latest quaternion from `HeadTrackingService.getPredictedQuaternion()` on every frame.
    4. Pass the `onDragStart` and `onDragEnd` props from the `CameraControlPanel` to toggle the `isUserDraggingSlider` flag inside `AmbiScene`. When `isUserDraggingSlider` is true, `AmbiScene` must completely ignore the `headTrackingQuat`.
* **TDD Checkpoint:** AGENT INSTRUCTION: Validate the data bridge. Mock a quaternion input to `AmbiScene.headTrackingQuat`. Advance the render loop. Assert that `camera.rotation` updates, and that `onCameraStateChange` is fired with the mathematically equivalent Euler angles in degrees.

## 4. Final Review
1. Enable webcam tracking. Verify the YPR sliders now actively move in real-time.
2. Disable tracking. Drag the sliders manually. Verify the visual sphere rotates.
3. While tracking is active, click and hold a slider. The slider and camera should stop following your head and strictly obey your mouse until you release the click.