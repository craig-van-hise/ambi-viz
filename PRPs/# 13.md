
## Product Requirements Prompt (PRP): Low-Latency Predictive Head Tracking

You are an elite Senior Feature Architect and developer agent operating within the Google Antigravity IDE (v1.14.2).

### A. Feature Context

You are adding Predictive Webcam Head Tracking to the existing AmbiViz codebase. Your goal is to implement this functionality while maintaining the integrity of the current system, specifically the `obr.wasm` WebAudio processing pipeline. The core objective is to achieve a motion-to-sound latency of below 60ms. Standard webcams and inference models introduce an inherent 90ms+ delay. Therefore, you must establish a lockless, multithreaded architecture (Web Worker communicating to an AudioWorklet via SharedArrayBuffer) and utilize advanced Asynchronous Timewarp prediction mathematics (the 1 Euro Filter and an Error-State Kalman Filter) to predict the user's head orientation 45ms into the future.

### B. Configuration Updates

* 
**Strict Memory & Architecture:** Utilize standard coding practices, maintaining strict separation of concerns between DOM manipulation (main thread), machine learning inference (Web Worker), and spatial audio processing (AudioWorklet). Ensure the `AudioWorkletProcessor` remains entirely non-blocking (no `Atomics.wait()` or predictable garbage collection).


* 
**Dependencies:** You must install the following packages before writing implementation code:


* 
`npm install @mediapipe/tasks-vision` (Required for the Face Landmarker API).


* 
`npm install -D gl-matrix` (Required for robust, optimized Quaternion and Matrix mathematics).




* 
**Security & Memory:** Ensure cross-origin isolation headers (`Cross-Origin-Opener-Policy: same-origin`, `Cross-Origin-Embedder-Policy: require-corp`) are configured in the application's development server to permit SharedArrayBuffer allocation.



### C. Phased Implementation & TDD Strategy

You are required to build this feature sequentially using Test-Driven Development (TDD) to ensure the highly sensitive audio thread is never compromised by blocking operations.

#### Phase 1: The "Walking Skeleton", Camera Init & Tests

* 
**Objective:** Establish the multithreaded plumbing, user media capture, and lockless memory synchronization.


* **Tasks:**
* 
**SAB Schema:** Define the SharedArrayBuffer memory schema precisely. Instantiate an `Int32Array` for Atomics flags (sequence numbers) and a `Float32Array` for the quaternion kinematics. Write the TypeScript interfaces required for the Main Thread, Worker, and Worklet message passing.


* 
**Audio Integration:** Write failing unit tests that assert the `AudioWorkletProcessor` can successfully read mock atomic data from the SAB without using `Atomics.wait()` or blocking the thread. Connect the SAB to the `obr.wasm` rotation API inside the AudioWorklet's `process()` method.


* **Main Thread Camera Capture:** Implement DOM manipulation in the main thread to request user webcam permissions via `navigator.mediaDevices.getUserMedia`, instantiate a hidden HTML `<video>` element, and pass the live video stream to the Web Worker.
* 
**Vision Worker:** Implement the MediaPipe FaceLandmarker initialization in a Web Worker, establish a loop synchronized to the incoming video element stream , extract the `pose_transform_matrix`, convert the $3\times3$ rotational submatrix to a unit quaternion , and write it to the SAB using `Atomics.store()`.




* 
**Regression Mandate:** Before marking a phase complete, you must run ALL existing tests to ensure this new feature has not broken previous functionality.


* **Checkpoint Law:** STOP. You are strictly forbidden from moving to the next phase until you run the tests and verify they PASS. **Once tests pass, you must open `localhost` and explicitly notify the user to test the raw webcam head tracking in the browser.**



#### Phase 2: Lightweight Predictive Tracking (Velocity Extrapolation & 1 Euro Filter)

* 
**Objective:** Implement Dead Reckoning and adaptive signal smoothing to combat static jitter and latency.


* **Tasks:**
* Write failing tests for a `OneEuroFilter` class, asserting that it applies heavy smoothing (low cutoff) at low simulated velocities, and minimal smoothing (high cutoff) at high velocities.


* Implement the 1 Euro Filter mathematical algorithm to smooth the incoming raw quaternions from MediaPipe.


* Calculate the Delta Quaternion between consecutive smoothed frames to derive the angular velocity vector $\omega$.


* Implement a constant velocity extrapolation algorithm to mathematically rotate the current quaternion into the future based on the extracted angular velocity .


* Write this predicted quaternion to the `QUAT_PRED` indices in the SAB.




* 
**Regression Mandate:** Before marking a phase complete, you must run ALL existing tests to ensure this new feature has not broken previous functionality.


* **Checkpoint Law:** STOP. You are strictly forbidden from moving to the next phase until you run the tests and verify they PASS. **Once tests pass, you must open `localhost` and explicitly notify the user to test the smoothed tracking implementation.**



#### Phase 3: Advanced Predictive Tracking (Error-State Kalman Filter)

* 
**Objective:** Replace naive velocity extrapolation with a robust 3DOF Error-State Kalman Filter (ESKF) to eliminate post-movement overshoot and appropriately model human biomechanical momentum.


* **Tasks:**
* Write unit tests for an ESKF class, specifically verifying that the nominal state successfully maintains a strict unit-norm constraint ($||q||=1$) after an error-state vector is injected into it.


* Implement the ESKF matrix mathematics. Define the continuous nominal state (quaternion and angular velocity) and the infinitesimal error state (a 3-dimensional rotation vector $\delta\theta$ residing in the tangent space, avoiding covariance singularity) .


* Implement the discrete-time prediction (time update) step. Calculate the Jacobian matrix $F_k$ of the non-linear system dynamics to propagate the covariance matrix $P$ forward in time alongside the nominal quaternion .


* Implement the measurement (correction) update step. Calculate the Kalman Gain $K_k$, compute the measurement residual against the noisy webcam data, and multiply to generate an observation of the error state.


* Inject the computed error state back into the nominal state using quaternion multiplication, and explicitly reset the error state to zero.


* Output the ESKF's predicted quaternion forward in time by $\tau=45ms$ to the SAB.




* 
**Regression Mandate:** Before marking a phase complete, you must run ALL existing tests to ensure this new feature has not broken previous functionality.


* **Checkpoint Law:** STOP. You are strictly forbidden from moving to the next phase until you run the tests and verify they PASS. **Once tests pass, you must open `localhost` and explicitly notify the user to test the final predictive head tracking pipeline.**

